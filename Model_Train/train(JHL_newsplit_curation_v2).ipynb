{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../model/\")\n",
    "# sys.path.append(\"../../loss/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/nas100_vol2/LeeJungHoon/Segmentation/OCT_task/Experiments_LJH'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import albumentations\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from unet_official import UNet\n",
    "from matplotlib import pyplot as plt\n",
    "from dice_score import multiclass_dice_coeff, dice_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# from torchsummary import summary\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "from skimage.filters import median\n",
    "from skimage.morphology import disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Seed Number 42\n"
     ]
    }
   ],
   "source": [
    "def seed_all(seed=42):\n",
    "    print(\"Using Seed Number {}\".format(seed))\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)  # set PYTHONHASHSEED env var at fixed value\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)  # pytorch (both CPU and CUDA)\n",
    "    np.random.seed(seed)  # for numpy pseudo-random generator\n",
    "    random.seed(seed)  # set fixed value for python built-in pseudo-random generator\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n",
    "def seed_worker(_worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "seed_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cache(filename):\n",
    "    return filename == '.ipynb_checkpoints'\n",
    "\n",
    "def del_cache(file_list):\n",
    "    if '.ipynb_checkpoints' in file_list:\n",
    "        file_list.remove('.ipynb_checkpoints')\n",
    "    if '@eaDir' in file_list:\n",
    "        file_list.remove('@eaDir')\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train image/mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/nas100_vol2/LeeJungHoon/Segmentation/OCT_task/Experiments_LJH'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2']\n"
     ]
    }
   ],
   "source": [
    "p = '../data/labeling'\n",
    "p_list = del_cache(os.listdir(p))\n",
    "print(p_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "root_path = \"../data/labeling\"\n",
    "curation_list = del_cache(os.listdir(root_path))\n",
    "patient_dict = {}\n",
    "\n",
    "for curation in curation_list:\n",
    "    patient_list = del_cache(os.listdir(f'{root_path}/{curation}'))\n",
    "    patient_dict[curation] = patient_list\n",
    "\n",
    "n = 0\n",
    "\n",
    "for curation, patient_list in patient_dict.items():\n",
    "    for patient_count, patient in enumerate(patient_list):\n",
    "        # 중증도별 image의 수를 맞추어주기 위해서 조건 걸어주기\n",
    "        # 한 번 돌려보고 모두 다 넣어서 학습 시켜보기\n",
    "        print(patient)\n",
    "        if patient_count == 8:\n",
    "            break\n",
    "        \n",
    "        laterality_list = del_cache(os.listdir(f'{root_path}/{curation}/{patient}'))\n",
    "\n",
    "        for laterality in laterality_list:\n",
    "            image_path_list = sorted([path for path in glob(f'{root_path}/{curation}/{patient}/{laterality}/train/image/*.png')])\n",
    "            mask_path_list = sorted([path for path in glob(f'{root_path}/{curation}/{patient}/{laterality}/train/mask/*.png')])\n",
    "\n",
    "            inputs += image_path_list\n",
    "            targets += mask_path_list\n",
    "            \n",
    "            n += len(image_path_list)\n",
    "    print(f'curation: {curation}, count: {n}')\n",
    "    n = 0\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "## origin file images 수 확인\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "root_path = \"../data/origin\"\n",
    "curation_list = del_cache(os.listdir(root_path))\n",
    "patient_dict = {}\n",
    "\n",
    "for curation in curation_list:\n",
    "    patient_list = del_cache(os.listdir(f'{root_path}/{curation}'))\n",
    "    patient_dict[curation] = patient_list\n",
    "\n",
    "n = 0\n",
    "\n",
    "for curation, patient_list in patient_dict.items():\n",
    "    for patient_count, patient in enumerate(patient_list):\n",
    "        # if patient_count == 8:\n",
    "        #     break\n",
    "        \n",
    "        laterality_list = del_cache(os.listdir(f'{root_path}/{curation}/{patient}'))\n",
    "\n",
    "        for laterality in laterality_list:\n",
    "            image_path_list = sorted([path for path in glob(f'{root_path}/{curation}/{patient}/{laterality}/*.png')])\n",
    "            mask_path_list = sorted([path for path in glob(f'{root_path}/{curation}/{patient}/{laterality}/*.png')])\n",
    "\n",
    "            inputs += image_path_list\n",
    "            targets += mask_path_list\n",
    "            \n",
    "            n += len(image_path_list)\n",
    "    print(f'curation: {curation}, count: {n}')\n",
    "    n = 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "patient_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = list(zip(inputs, targets))\n",
    "random.shuffle(dataset)\n",
    "inputs, targets = zip(*dataset)\n",
    "\n",
    "# 간단하게 확인\n",
    "print(inputs[:2])\n",
    "print(targets[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## device 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_NUM = 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "print('gpu? ', torch.cuda.is_available())\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print('Current gpu: ', torch.cuda.current_device())\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(GPU_NUM)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(GPU_NUM)/1024**3,1), 'GB')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches(img, mask, overlap=0.0, patch_size=256):\n",
    "    h, w = np.shape(img)\n",
    "    \n",
    "    img_patch_list = []\n",
    "    mask_patch_list = []\n",
    "    \n",
    "    patch_num = math.ceil((w - h) / (h * (1 - overlap))) + 1\n",
    "    \n",
    "    for w_start_idx in np.linspace(0, w-h, patch_num):\n",
    "        w_start_idx = int(w_start_idx)\n",
    "        img_patch = img[:, w_start_idx:w_start_idx+h]\n",
    "        mask_patch = mask[:, w_start_idx:w_start_idx+h]\n",
    "        \n",
    "        X_per = patch_size / h\n",
    "        resized_img = cv2.resize(img_patch, dsize=(0, 0), fx=X_per, fy=X_per, interpolation=cv2.INTER_NEAREST)\n",
    "        img_patch_list.append(resized_img)\n",
    "        \n",
    "        resized_mask = cv2.resize(mask_patch, dsize=(0, 0), fx=X_per, fy=X_per, interpolation=cv2.INTER_NEAREST)\n",
    "        mask_patch_list.append(resized_mask)\n",
    "        \n",
    "    return img_patch_list, mask_patch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_artifact(img, mask, filter_size=(1, 5), overlap=0.4, threshold = 25):\n",
    "    MEAN_VALUE = 127.5\n",
    "    removed_img = img.copy()\n",
    "    \n",
    "    mask_h, mask_w = mask.shape\n",
    "    filter_h, filter_w = filter_size[0], filter_size[1]\n",
    "    \n",
    "    patch_num = math.ceil((mask_w - filter_w) / (filter_w * (1 - overlap))) + 1\n",
    "    \n",
    "    for h_start_idx in range(0, mask_h, filter_h):\n",
    "        for w_start_idx in np.linspace(0, mask_w-filter_w, patch_num):\n",
    "            w_start_idx = int(w_start_idx)\n",
    "            mask_region = mask[h_start_idx:h_start_idx+filter_h, w_start_idx:w_start_idx+filter_w]\n",
    "            mask_region_unique_value = np.unique(mask_region)\n",
    "            \n",
    "            if 0 in mask_region_unique_value or 10 in mask_region_unique_value:\n",
    "                continue\n",
    "            \n",
    "            img_region = removed_img[h_start_idx:h_start_idx+filter_h, w_start_idx:w_start_idx+filter_w]\n",
    "            \n",
    "            for h in range(filter_h):\n",
    "                pixel_list = img_region[h, :]\n",
    "                mean_pixel = int(np.mean(pixel_list))\n",
    "                \n",
    "                less = [element for element in pixel_list if element < mean_pixel] + [mean_pixel]\n",
    "                greater = [element for element in pixel_list if element > mean_pixel] + [mean_pixel]\n",
    "\n",
    "                for idx, element in enumerate(pixel_list): \n",
    "                    # 대체적으로 밝다\n",
    "                    if mean_pixel > MEAN_VALUE and element - mean_pixel <= -threshold:\n",
    "                        pixel_list[idx] = random.choice(greater)\n",
    "                    # 대체적으로 어둡다\n",
    "                    elif mean_pixel < MEAN_VALUE and element - mean_pixel >= threshold:\n",
    "                        pixel_list[idx] = random.choice(less)      \n",
    "    return removed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_artifact(img, mask, name, threshold=2):\n",
    "    removed_img = img.copy()\n",
    "    \n",
    "    # 배경과 맥랙막을 제외한 망막 layer들\n",
    "    for label_num in range(1, 10):\n",
    "        mask_region = mask == label_num\n",
    "        \n",
    "        if len(mask_region) == 0:\n",
    "            print(f'{label_num} >>> {name}')\n",
    "        img_region = removed_img[mask_region]\n",
    "        \n",
    "        mean = np.mean(img_region)\n",
    "        std = np.std(img_region)\n",
    "        \n",
    "        outlier = [] \n",
    "        normal = []\n",
    "        \n",
    "        for pixel in img_region:\n",
    "            z_score = abs(pixel - mean) / std \n",
    "\n",
    "            if z_score > threshold: \n",
    "                outlier.append(pixel)\n",
    "            else:\n",
    "                normal.append(pixel)\n",
    "\n",
    "        for idx, pixel in enumerate(img_region):\n",
    "            if pixel in outlier:\n",
    "                img_region[idx] = random.choice(normal)\n",
    "                \n",
    "        removed_img[mask_region] = img_region\n",
    "        \n",
    "    return removed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/nas100_vol2/LeeJungHoon/Segmentation/OCT_task/Experiments_LJH'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = '../data/train_data/V2/train/image/*.png' \n",
    "train_mask_path = '../data/train_data/V2/train/mask/*.png' \n",
    "\n",
    "valid_image_path = '../data/train_data/V2/valid/image/*.png' \n",
    "valid_mask_path = '../data/train_data/V2/valid/mask/*.png' \n",
    "\n",
    "test_image_path = '../data/train_data/V2/test/image/*.png' \n",
    "test_mask_path = '../data/train_data/V2/test/mask/*.png' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = glob(train_image_path)\n",
    "c = glob(train_mask_path)\n",
    "\n",
    "for a, b in zip(b, c):\n",
    "    print(a,b)\n",
    "    img = cv2.imread(a, cv2.IMREAD_GRAYSCALE)\n",
    "    ma = cv2.imread(b, cv2.IMREAD_GRAYSCALE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCT_Dataset(Dataset):\n",
    "    def __init__(self, image_path, mask_path, transform_with_mask=None):\n",
    "        self.image_path_list = sorted(glob(image_path))\n",
    "        self.mask_path_list = sorted(glob(mask_path))\n",
    "        \n",
    "        self.image_list = []\n",
    "        self.mask_list = []\n",
    "        \n",
    "        self.transform_with_mask = transform_with_mask\n",
    "        \n",
    "        \n",
    "        for (image_path, mask_path) in zip(self.image_path_list, self.mask_path_list):\n",
    "            \n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            '''\n",
    "            # RAA\n",
    "            image = median(image, disk(1))\n",
    "            mask = median(mask, disk(5))\n",
    "            \n",
    "            # RVA\n",
    "            image = remove_artifact(image, mask, image_path, threshold=1.5)            \n",
    "            '''\n",
    "            \n",
    "            # Aug\n",
    "            # image = np.expand_dims(image, axis=0)\n",
    "            \n",
    "            if self.transform_with_mask:\n",
    "\n",
    "                image = np.squeeze(image)\n",
    "\n",
    "                augmented = self.transform_with_mask(image=image, mask=mask)\n",
    "                augmented_image, augmented_mask = augmented['image'], augmented['mask']\n",
    "            \n",
    "                augmented_image = np.expand_dims(augmented_image, axis=0)\n",
    "                # augmented_mask = np.expand_dims(augmented_mask, axis=0)\n",
    "                \n",
    "                # print(augmented_image.shape)\n",
    "                # print(augmented_mask.shape)\n",
    "                \n",
    "                # 동환 선생님이 했던 것과 순서가 다름 원래와 같은 순서대로 들어갈 경우 같은 data가 두 번 들어가기 때문에 \n",
    "                # append하는 부분을 마지막에 추가해주기\n",
    "                # self.image_list.append(torch.from_numpy(augmented_image).float())\n",
    "                # self.mask_list.append(torch.from_numpy(augmented_mask).float())\n",
    "                            \n",
    "                self.image_list.append(torch.from_numpy(augmented_image).float())\n",
    "                self.mask_list.append(torch.from_numpy(augmented_mask).float())\n",
    "            \n",
    "            else:\n",
    "                image = np.expand_dims(image, axis=0)\n",
    "                # mask = np.expand_dims(mask, axis=0)\n",
    "                \n",
    "                self.image_list.append(torch.from_numpy(image).float())\n",
    "                self.mask_list.append(torch.from_numpy(mask).float())\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return {'image': self.image_list[idx], 'mask': self.mask_list[idx], 'filename' : self.image_path_list[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size : 663\n",
      "Validation Data Size : 78\n",
      "Testing Data Size : 104\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "# dataset_size = len(inputs)\n",
    "# # Augmentation 이후 train:valid:test 비율이 \n",
    "# # 6:2:2 => 3/7, 2/7\n",
    "# # 8:1:1 => 2/3, 1/6\n",
    "\n",
    "# train_size = round(dataset_size * 0.8)\n",
    "# validation_size = round(dataset_size * 0.1)\n",
    "# test_size = dataset_size - train_size - validation_size\n",
    "# print(dataset_size)\n",
    "# print(f'{train_size}:{validation_size}:{test_size}')\n",
    "\n",
    "train_transform_with_mask = albumentations.Compose([\n",
    "    albumentations.ShiftScaleRotate(shift_limit=0, scale_limit=(0,0.2), rotate_limit=0, p=0.3, interpolation=1, border_mode=cv2.BORDER_REPLICATE),\n",
    "    albumentations.RandomCropFromBorders(crop_left=0, crop_right=0, crop_top=0.05, crop_bottom=0.05, always_apply=False, p=0.3),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.CLAHE(clip_limit=(1,2), p=0.3),\n",
    "    albumentations.Resize(512,512, interpolation = cv2.INTER_AREA)    \n",
    "    ])\n",
    "\n",
    "transform_with_mask = albumentations.Resize(512,512, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "train_dataset = OCT_Dataset(train_image_path, train_mask_path, transform_with_mask)\n",
    "validation_dataset = OCT_Dataset(valid_image_path, valid_mask_path, transform_with_mask)\n",
    "test_dataset = OCT_Dataset(test_image_path, test_mask_path, transform_with_mask)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, worker_init_fn=seed_worker)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "print(f\"Training Data Size : {len(train_dataset)}\")\n",
    "print(f\"Validation Data Size : {len(validation_dataset)}\")\n",
    "print(f\"Testing Data Size : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10554838_OD_05.png'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(validation_dataset[0]['mask'].shape)\n",
    "train_dataset[0]['filename'].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(validation_dataloader):\n",
    "    if idx == 10:\n",
    "        break\n",
    "    images = batch['image']\n",
    "    targets = batch['mask']\n",
    "    print(images.type)\n",
    "    print(images.shape)\n",
    "    print(targets.shape)\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(images[0].squeeze(), cmap='gray')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(targets[0].squeeze(), cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "참고: https://deep-learning-study.tistory.com/706\n",
    "\n",
    "\n",
    "def dice_score(pred, target, smooth = 1e-5):\n",
    "    # binary cross entropy loss\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target, reduction='sum')\n",
    "    \n",
    "    pred = torch.sigmoid(pred)\n",
    "    intersection = (pred * target).sum(dim=(2,3))\n",
    "    union = pred.sum(dim=(2,3)) + target.sum(dim=(2,3))\n",
    "    \n",
    "    # dice coefficient\n",
    "    dice = 2.0 * (intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    return dice\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = UNet(1, 11).to(device)\n",
    "# summary(net, (1, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "# scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "def train_one_epoch(training_loader, epoch, tb_writer):\n",
    "    running_loss = 0.0\n",
    "    total_dice_score = 0.0\n",
    "    num_train_batches = len(training_loader)\n",
    "    dice_score_per_layer = {}\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        '''\n",
    "        images = []\n",
    "        targets = []\n",
    "        \n",
    "        for image, mask in zip(batch['image'], batch['mask']):\n",
    "            augmented = transform(image=image.numpy(), mask=mask.numpy())\n",
    "            image, mask = augmented['image'], augmented['mask']\n",
    "\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "\n",
    "            images.append(image)\n",
    "            targets.append(mask)\n",
    "\n",
    "        images = torch.from_numpy(np.array(images)).to(device=device, dtype=torch.float32)\n",
    "        targets = torch.from_numpy(np.array(targets)).to(device=device, dtype=torch.long)\n",
    "        '''\n",
    "        \n",
    "        images = batch['image'].to(device=device, dtype=torch.float32)\n",
    "        targets = batch['mask'].to(device=device, dtype=torch.long)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        masks_pred = net(images)\n",
    "        \n",
    "        \n",
    "        loss = criterion(masks_pred, targets)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # running_loss_arr += [loss.item()]\n",
    "        # batch_mean_loss = np.mean(running_loss_arr)\n",
    "        \n",
    "        targets = F.one_hot(targets, net.n_classes).permute(0, 3, 1, 2).float()\n",
    "        masks_pred = F.one_hot(masks_pred.argmax(dim=1), net.n_classes).permute(0, 3, 1, 2).float()\n",
    "    \n",
    "        dice_score, dice_score_list = multiclass_dice_coeff(masks_pred[:, 1:, ...], targets[:, 1:, ...], reduce_batch_first=False)\n",
    "        total_dice_score += dice_score\n",
    "        \n",
    "        batch_dice_score_per_layer = {idx + 1: dice_score.item() for idx, dice_score in enumerate(dice_score_list)}\n",
    "        \n",
    "        for layer, dice_score in batch_dice_score_per_layer.items():\n",
    "            if dice_score_per_layer.get(layer) == None:\n",
    "                dice_score_per_layer[layer] = dice_score\n",
    "            else:\n",
    "                dice_score_per_layer[layer] += dice_score\n",
    "    else:\n",
    "        last_loss = running_loss / num_train_batches\n",
    "        avg_vscore = total_dice_score / num_train_batches\n",
    "        train_dice_score_per_layer = {layer: round(dice_score / num_train_batches, 3) for layer, dice_score in dice_score_per_layer.items()}\n",
    "        \n",
    "        print(f'| epoch {epoch} |\\ntrain loss: {last_loss:.3f} \\ntrain dice_score: {avg_vscore:.3f} \\ntrain_dice_score_per_layer: {json.dumps(train_dice_score_per_layer, sort_keys = False, indent = 4)}')\n",
    "        tb_writer.add_scalar('Loss/train', last_loss, epoch)\n",
    "        tb_writer.add_scalar('Dice_Score/train', avg_vscore, epoch)\n",
    "    return last_loss, avg_vscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "os.mkdir(f'/mnt/nas100_vol2/LeeJungHoon/Segmentation/OCT_task/checkpoints/train(JHL_newsplit_curation_v2)')\n",
    "# writer = SummaryWriter(f'../runs/{timestamp}')\n",
    "writer = SummaryWriter('/mnt/nas100_vol2/LeeJungHoon/Segmentation/OCT_task/runs/train(JHL_newsplit_curation_v2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "best_vloss = 1_000_000.0\n",
    "best_vscore = 0.0\n",
    "num_val_batches = len(validation_dataloader)\n",
    "\n",
    "loss_history = {'train': [], 'val': []}\n",
    "metric_history = {'train': [], 'val': []}\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    net.train()\n",
    "    avg_loss, avg_vscore = train_one_epoch(train_dataloader, epoch, writer)\n",
    "    loss_history['train'].append(avg_loss)\n",
    "    metric_history['train'].append(avg_vscore)\n",
    "\n",
    "    \n",
    "    net.eval()\n",
    "    running_vloss = 0.0\n",
    "    total_dice_score = 0.0\n",
    "    dice_score_per_layer = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(validation_dataloader):\n",
    "            images = batch['image']\n",
    "            targets = batch['mask']\n",
    "\n",
    "#             images = images.unsqueeze(1)\n",
    "        \n",
    "            images = images.to(device=device, dtype=torch.float32)\n",
    "            targets = targets.to(device=device, dtype=torch.long)\n",
    "\n",
    "            masks_pred = net(images)\n",
    "            # print(masks_pred.shape)\n",
    "            loss = criterion(masks_pred, targets)\n",
    "            \n",
    "            running_vloss += loss\n",
    "            \n",
    "            targets = F.one_hot(targets, net.n_classes).permute(0, 3, 1, 2).float()\n",
    "            masks_pred = F.one_hot(masks_pred.argmax(dim=1), net.n_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "            dice_score, dice_score_list = multiclass_dice_coeff(masks_pred[:, 1:, ...], targets[:, 1:, ...], reduce_batch_first=False)\n",
    "            total_dice_score += dice_score\n",
    "            \n",
    "            for idx, dice_score in enumerate(dice_score_list):\n",
    "                if dice_score_per_layer.get(idx + 1) == None:\n",
    "                    dice_score_per_layer[idx + 1] = dice_score.item()\n",
    "                else:\n",
    "                    dice_score_per_layer[idx + 1] += dice_score.item()\n",
    "    \n",
    "    avg_vloss = running_vloss / num_val_batches\n",
    "    avg_val_vscore = total_dice_score / num_val_batches\n",
    "    valid_dice_score_per_layer = {layer: round(dice_score / num_val_batches, 3) for layer, dice_score in dice_score_per_layer.items()}\n",
    "    \n",
    "#     scheduler.step(avg_vloss)\n",
    "    print(f'valid loss: {avg_vloss:.3f} \\nvalid dice_score: {avg_val_vscore:.3f} \\nvalid_dice_score_per_layer: {json.dumps(valid_dice_score_per_layer, sort_keys=False, indent=4)}')\n",
    "    \n",
    "    writer.add_scalar('Loss/valid', avg_vloss, epoch)\n",
    "    writer.add_scalar('Dice_Score/valid', avg_vscore, epoch)\n",
    "    \n",
    "    loss_history['val'].append(avg_vloss)\n",
    "    metric_history['val'].append(avg_val_vscore)\n",
    "        \n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        \n",
    "        path = f'/mnt/nas100_vol2/LeeJungHoon/Segmentation/OCT_task/checkpoints/train(JHL_newsplit_curation_v2)/best_loss_{epoch}.pth'\n",
    "        torch.save(net.state_dict(), path)\n",
    "\n",
    "    if avg_vscore > best_vscore:\n",
    "        best_vscore = avg_vscore\n",
    "        \n",
    "        path = f'/mnt/nas100_vol2/LeeJungHoon/Segmentation/OCT_task/checkpoints/train(JHL_newsplit_curation_v2)/best_score_{epoch}.pth'\n",
    "        torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Dice loss')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = metric_history['train']\n",
    "val_accuracy = metric_history['val'] \n",
    "\n",
    "loss = loss_history['train'] \n",
    "val_loss = loss_history['val']\n",
    "\n",
    "epochs = range(len(loss_history['train']))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, accuracy, label=\"train\") \n",
    "plt.plot(epochs, val_accuracy, label=\"val\")\n",
    "plt.xlabel('epochs')\n",
    "plt.legend() \n",
    "plt.title('Dice Score') \n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# plt.figure()\n",
    "plt.plot(epochs, loss, label=\"train\")\n",
    "plt.plot(epochs, val_loss, label=\"val\") \n",
    "plt.xlabel('epochs')\n",
    "plt.legend() \n",
    "plt.title('Dice loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화를 위한 RGB값\n",
    "\n",
    "mask_rgb = {\n",
    "    0: [0, 0, 0],\n",
    "    1: [255, 0, 0],\n",
    "    2: [0, 255, 0],\n",
    "    3: [0, 0, 255],\n",
    "    4: [255, 255, 0],\n",
    "    5: [0, 255, 255],\n",
    "    6: [255, 0, 255],\n",
    "    7: [208, 200, 187],\n",
    "    8: [93, 93, 195],\n",
    "    9: [207, 171, 136],\n",
    "    10: [221, 206, 186],\n",
    "    11: [51, 204, 204]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_to_rgb(gray_image):\n",
    "    rgb_img = np.zeros((512, 512, 3))\n",
    "    \n",
    "    for layer, rgb_value in mask_rgb.items():\n",
    "        class_region = gray_image == layer\n",
    "        rgb_img[class_region.cpu()] = rgb_value\n",
    "        \n",
    "    return rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \"best_loss_25.pth\"\n",
    "checkpoint_path = f\"/mnt/nas100_vol2/LeeJungHoon/Segmentation/OCT_task/checkpoints/train(JHL_newsplit_curation_v2)/{filename}\" \n",
    "net.load_state_dict(torch.load(checkpoint_path))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 이미지 저장 폴더 생성\n",
    "os.mkdir(f'/mnt/nas100_vol2/LeeJungHoon/Segmentation/OCT_task/test_results/train(JHL_newsplit_curation)')\n",
    "save_path = '/mnt/nas100_vol2/LeeJungHoon/Segmentation/OCT_task/test_results/train(JHL_newsplit_curation)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_tonumpy = lambda x : x.to('cpu').detach().numpy().transpose(1,2,0)\n",
    "# net.eval()\n",
    "test_loss = 0.0\n",
    "test_dice_score = 0.0\n",
    "dice_score_per_layer = {}\n",
    "num_test_batches = len(test_dataloader)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for idx, batch in enumerate(test_dataloader):\n",
    "        \n",
    "        images = batch['image']\n",
    "        targets = batch['mask']\n",
    "        \n",
    "        name = batch['filename']\n",
    "    \n",
    "        last_name = name[0].split('/')[-1]\n",
    "        patient = last_name.split('_')[0]\n",
    "        lateral = last_name.split('_')[1]\n",
    "        img_num_png = last_name.split('_')[2]\n",
    "        img_num = re.split('[.]+', img_num_png)[0]\n",
    "\n",
    "        images = images.to(device=device, dtype=torch.float32)\n",
    "        targets = targets.to(device=device, dtype=torch.long)\n",
    "\n",
    "        masks_pred = net(images)\n",
    "\n",
    "        loss = criterion(masks_pred, targets)\n",
    "\n",
    "        test_loss += loss\n",
    "        \n",
    "        masks_pred = masks_pred.argmax(dim=1)\n",
    "        \n",
    "        # for image, target, pred_array in zip(images, targets, masks_pred):\n",
    "        # print(targets.squeeze().shape)\n",
    "        target_img = gray_to_rgb(targets.squeeze())\n",
    "        pred_img = gray_to_rgb(masks_pred.squeeze())\n",
    "\n",
    "        #결과 이미지 저장\n",
    "        imgs = np.hstack((target_img, pred_img))\n",
    "        # print(imgs.shape)\n",
    "        plt.imshow(imgs.astype('uint8'))\n",
    "        # print(f'{save_path}/{patient}_{lateral}_{img_num}')\n",
    "        print(patient)\n",
    "        print(img_num)\n",
    "        # plt.imsave(os.path.join(save_path, '%s_%s_%s.png' % (patient, lateral, img_num)), imgs.astype('uint8'))\n",
    "\n",
    "        # destination = f'{save_path}'\n",
    "        # save = shutil.copy2(imgs, f\"{destination}/{patient}_{lateral}_{img_num}\")\n",
    "\n",
    "        fig = plt.figure(figsize=(20, 20)) \n",
    "\n",
    "        print(images.squeeze(0).shape)\n",
    "        print(target_img.shape)\n",
    "        \n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(fn_tonumpy(images.cpu().squeeze(0)), cmap = plt.cm.gray)\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(target_img.astype('uint8'))\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred_img.astype('uint8'))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        targets = F.one_hot(targets, net.n_classes).permute(0, 3, 1, 2).float()\n",
    "        masks_pred = F.one_hot(masks_pred, net.n_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "        dice_score, dice_score_list = multiclass_dice_coeff(masks_pred[:, 1:, ...], targets[:, 1:, ...], reduce_batch_first=False)\n",
    "        test_dice_score += dice_score\n",
    "\n",
    "        for idx, dice_score in enumerate(dice_score_list):\n",
    "            if dice_score_per_layer.get(idx + 1) == None:\n",
    "                dice_score_per_layer[idx + 1] = dice_score.item()\n",
    "            else:\n",
    "                dice_score_per_layer[idx + 1] += dice_score.item()\n",
    "                \n",
    "avg_test_loss = test_loss / num_test_batches\n",
    "avg_test_score = test_dice_score / num_test_batches\n",
    "test_dice_score_per_layer = {layer: round(dice_score / num_test_batches, 3) for layer, dice_score in dice_score_per_layer.items()}\n",
    "\n",
    "print(f'test loss: {avg_test_loss:.3f} \\ntest dice_score: {avg_test_score:.3f} \\ntest_dice_score_per_layer: {json.dumps(test_dice_score_per_layer, sort_keys=False, indent=4)}')\n",
    "\n",
    "writer.add_scalar('Loss/test', avg_test_loss, epoch)\n",
    "writer.add_scalar('Dice_Score/test', avg_test_score, epoch)\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 1024, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
